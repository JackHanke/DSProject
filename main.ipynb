{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Classification for Genomic Data\n",
    "The main file for testing of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import preprocessors\n",
    "from data.preprocess_data import RawData, MinMaxScaledData, StandardScaledData\n",
    "# import third party various libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal # dan and his typing\n",
    "from collections import defaultdict\n",
    "# small army of sklearn imports\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectKBest, f_classif\n",
    "# import specific models \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# stop warning me\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_gene` function translates the dummy ID from the dataset to the real gene name. The gene name is formatted into two parts split by a `|` character. The first part is the [GeneCards](https://www.genecards.org/) gene identifier, and the second is the [National Library of Medicine](https://www.ncbi.nlm.nih.gov/) gene identifier. Both are uniquely identifying, but there are 29 genes with no GeneCards identifier, marked with a '?' symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gene with index 3523: CDX1|1044\n"
     ]
    }
   ],
   "source": [
    "def get_gene(index):\n",
    "    # csv file made from original data source file unc.edu_PANCAN_IlluminaGA_RNASeqV2.geneExp.tsv at https://www.synapse.org/#!Synapse:syn4301332\n",
    "    df = pd.read_csv('gene_ids.csv') \n",
    "    result = df.loc[df['dummy_id'] == index]\n",
    "    return result['gene_id'].values[0]\n",
    "\n",
    "index = 3523 # gene we later learn is associated with colon cancer\n",
    "gene = get_gene(index = index)\n",
    "print(f'The gene with index {index}: {gene}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit_and_val_classifier` function is a general function for testing an `sklearn` classifier on the preprocessed dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "raw_data = RawData()\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = raw_data.get_data()\n",
    "\n",
    "def fit_and_val_sklearn_classifier(classifier, X_train=X_train, X_val=X_val, verbose=False):\n",
    "    start = time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    if verbose: print(f'Classifier fit in {(time()-start):.3f}s')\n",
    "    y_pred_val = classifier.predict(X_val)\n",
    "    val_acc = accuracy_score(y_true=y_val, y_pred=y_pred_val)\n",
    "    if verbose: \n",
    "        print(f'Validation accuracy: {(val_acc*100):.3f}%\\nClassification Report (Validation):\\n{classification_report(y_val, y_pred_val)}')\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table of Results\n",
    "*Note that the below cell may take a while to run, as it fits a large number of models*\n",
    "\n",
    "We next generate a summary of how different models, hyperparameters, and preprocessing methods affect the validation accuracy. We use this table to decide that the best combination for modeling is TODO. In general, we see high performance accross many types of tree-based and linear models. \n",
    "\n",
    "The rest of the file shows specifics for different models and  data-preprocessing methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Raw Data</th>\n",
       "      <th>MinMax Scaled Data</th>\n",
       "      <th>Standard Scaled Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>96.92</td>\n",
       "      <td>96.92</td>\n",
       "      <td>96.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier(n_estimators=10, random_sta...</td>\n",
       "      <td>98.46</td>\n",
       "      <td>98.46</td>\n",
       "      <td>98.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier(n_estimators=5, ran...</td>\n",
       "      <td>99.23</td>\n",
       "      <td>99.23</td>\n",
       "      <td>99.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Models  Raw Data  \\\n",
       "0            DecisionTreeClassifier(random_state=42)     96.92   \n",
       "1            RandomForestClassifier(random_state=42)    100.00   \n",
       "2  AdaBoostClassifier(n_estimators=10, random_sta...     98.46   \n",
       "3  GradientBoostingClassifier(n_estimators=5, ran...     99.23   \n",
       "4                LogisticRegression(random_state=42)    100.00   \n",
       "\n",
       "   MinMax Scaled Data  Standard Scaled Data  \n",
       "0               96.92                 96.92  \n",
       "1              100.00                100.00  \n",
       "2               98.46                 98.46  \n",
       "3               99.23                 99.23  \n",
       "4              100.00                100.00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def make_val_summary_table(models_lst, preprocessed_data_lst):\n",
    "    df_dict = {'Models':[]}\n",
    "    for index, data_obj in enumerate(preprocessed_data_lst):\n",
    "        data_source = data_obj.get_data()\n",
    "        # ds_name = data_source.name\n",
    "        ds_name = data_obj.name\n",
    "        df_dict[ds_name] = []\n",
    "        for model in models_lst:\n",
    "            if index == 0: df_dict['Models'].append(str(model))\n",
    "            val_acc = fit_and_val_sklearn_classifier(\n",
    "                classifier=model,\n",
    "                X_train=data_source[0],\n",
    "                X_val=data_source[2],\n",
    "            )\n",
    "            if val_acc > 0.999 and index == 0: # save model\n",
    "                path_str = f'savedmodels/{str(model)}.pkl'\n",
    "                with open(path_str, 'wb') as f:\n",
    "                    pickle.dump(model, file=f)\n",
    "            df_dict[ds_name].append(val_acc*100)\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    return df\n",
    "\n",
    "rand_state = 42 # \n",
    "summary_table = make_val_summary_table(\n",
    "    models_lst = [\n",
    "        DecisionTreeClassifier(random_state=rand_state),\n",
    "        RandomForestClassifier(random_state=rand_state),\n",
    "        AdaBoostClassifier(n_estimators=10, random_state=rand_state),\n",
    "        GradientBoostingClassifier(n_estimators=5, random_state=rand_state),\n",
    "        LogisticRegression(random_state=rand_state),\n",
    "    ],\n",
    "    preprocessed_data_lst = [\n",
    "        RawData(),\n",
    "        MinMaxScaledData(),\n",
    "        StandardScaledData(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pd.set_option('display.precision', 2) # set the precision of the accuracy in the table\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Values - Nicole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "print('--- Random Forest ---')\n",
    "val_acc = fit_and_val_sklearn_classifier(classifier=model, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def shapley_value_reduce(model, k=1000):\n",
    "    # Calculate Shapley values\n",
    "    explainer = shap.TreeExplainer(model)  \n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "    # mean absolute Shapley value for each feature \n",
    "    shap_values_mean = np.abs(shap_values).mean(axis=0)  \n",
    "\n",
    "    top_k_features = np.argsort(shap_values_mean)[-k:]  \n",
    "    selected_features = X_train.columns[top_k_features.flatten()]\n",
    "\n",
    "    X_train_reduced = X_train[selected_features]\n",
    "    X_val_reduced = X_val[selected_features] \n",
    "    X_test_reduced = X_test[selected_features]\n",
    "\n",
    "    return X_train_reduced, X_val_reduced, X_test_reduced\n",
    "\n",
    "# model from previous cell\n",
    "X_train_reduced, X_val_reduced, X_test_reduced = shapley_value_reduce(model)\n",
    "\n",
    "model_reduced = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "val_acc = fit_and_val_sklearn_classifier(\n",
    "    classifier = model_reduced,\n",
    "    X_train = X_train_reduced,\n",
    "    X_val = X_val_reduced,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest w/ ANOVA - Nicole\n",
    "TODO explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_feature_performance(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    y_train = y_train.values.ravel() if hasattr(y_train, 'values') else y_train.ravel()\n",
    "    y_val = y_val.values.ravel() if hasattr(y_val, 'values') else y_val.ravel()\n",
    "    y_test = y_test.values.ravel() if hasattr(y_test, 'values') else y_test.ravel()\n",
    "\n",
    "    variance_selector = VarianceThreshold(threshold=0.01)\n",
    "    X_train_var = variance_selector.fit_transform(X_train)\n",
    "    X_val_var = variance_selector.transform(X_val)\n",
    "    X_test_var = variance_selector.transform(X_test)\n",
    "\n",
    "    k_best_selector = SelectKBest(f_classif, k=5000)\n",
    "    X_train_kbest = k_best_selector.fit_transform(X_train_var, y_train)\n",
    "    X_val_kbest = k_best_selector.transform(X_val_var)\n",
    "    X_test_kbest = k_best_selector.transform(X_test_var)\n",
    "\n",
    "    base_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    base_model.fit(X_train_kbest, y_train)\n",
    "\n",
    "    importances = base_model.feature_importances_\n",
    "    top_indices = np.argsort(importances)[-1000:]\n",
    "\n",
    "    X_train_final = X_train_kbest[:, top_indices]\n",
    "    X_val_final = X_val_kbest[:, top_indices]\n",
    "    X_test_final = X_test_kbest[:, top_indices]\n",
    "    \n",
    "    return X_train_final, X_val_final, X_test_final\n",
    "\n",
    "X_train_final, X_val_final, X_test_final = filter_by_feature_performance(\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test\n",
    ")\n",
    "\n",
    "final_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "fit_and_val_sklearn_classifier(\n",
    "    classifier=final_model,\n",
    "    X_train=X_train_final,\n",
    "    X_val=X_val_final,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "y_pred_test = final_model.predict(X_test_final)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Classification Report (Test):\\n\", classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Regression - Hanna\n",
    "TODO explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#initialize logistic regression model, configured for multinomial classificaiton (>2 classes), using 'lbfgs' solver\n",
    "#the 'max_iter' parameter ensures sufficient iterations for convergence, and 'random_state' ensures reproducibility\n",
    "#https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "\n",
    "print(f'--- Logistic Regression ---')\n",
    "val_acc = fit_and_val_sklearn_classifier(classifier=log_reg, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means with PCA - Hanna\n",
    "TODO explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# #load data; load the feature data and labels from Parquet files into Pandas DataFrames\n",
    "# #the 'data.parquet' file contains the features, while 'labels.parquet' contains the target class labels\n",
    "# #https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html\n",
    "# data = pd.read_parquet('data.parquet')\n",
    "# labels = pd.read_parquet('labels.parquet')\n",
    "\n",
    "# #map the labels to an encoding dicitonary to ensure consistent class mapping\n",
    "# labels['Class'] = labels['Class'].map(encoding_dict)\n",
    "\n",
    "# #rename columns for readability and usability\n",
    "# #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html\n",
    "# data.rename(columns={'Unnamed: 0': 'sample_id'}, inplace=True)\n",
    "# labels.rename(columns={'Unnamed: 0': 'sample_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# #merge datasets; combine the features and labels intoa single DataFrame, joining on the common column 'sample_id'\n",
    "# #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html\n",
    "# merged_data = pd.merge(data, labels, on='sample_id')\n",
    "\n",
    "# #drop the sample_id column as it isn't needed for analaysis\n",
    "# #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "# #features\n",
    "# data = merged_data.drop(columns=['sample_id', 'Class'])\n",
    "# #labels\n",
    "# labels = merged_data['Class']\n",
    "\n",
    "# #standardize features with StandardScalar to normalize values, ensuring each feature has a mean of 0 and\n",
    "# # a standard deviation of 1\n",
    "# #https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "# scaler = StandardScaler()\n",
    "# #fit and transform the training data\n",
    "# data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = StandardScaledData().get_data()\n",
    "\n",
    "\n",
    "#Grid Search CV: https://www.analyticsvidhya.com/blog/2021/06/tune-hyperparameters-with-gridsearchcv/\n",
    "def pca_grid_search(data, components_range):\n",
    "    results = {}\n",
    "    for n in components_range:\n",
    "        pca = PCA(n_components=n, random_state=42)\n",
    "        reduced_data = pca.fit_transform(data)\n",
    "        variance_explained = sum(pca.explained_variance_ratio_)\n",
    "        results[n] = variance_explained\n",
    "    return results\n",
    "\n",
    "#perform PCA grid search\n",
    "#components_range = rcomponents_range = range(200, min(data_scaled.shape[1], 801), 50) # Include up to 801 or total features - 2 minutes and 6.4 seconds\n",
    "max_components = min(500, X_train.shape[1]) # Limit to 500 components or feature count\n",
    "components_range = range(50, max_components, 50) # Start from 50 with a step of 50\n",
    "variance_results = pca_grid_search(data=X_train, components_range=components_range)\n",
    "\n",
    "#find the optimal number of components (e.g., retain ~95% variance)\n",
    "optimal_components = max(k for k, v in variance_results.items() if v >= 0.85)\n",
    "\n",
    "#apply PCA for dimensionality reduction: reduce the feature set to 20 principlal components to simplify the dataset\n",
    "# while retraining as much variance as possible\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "pca = PCA(n_components=optimal_components, random_state=42)\n",
    "data_reduced = pca.fit_transform(X_train)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_val_reduced = pca.transform(X_val)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "labels = y_train # TODO remove \n",
    "encoding_dict = {\n",
    "    'BRCA': 0,\n",
    "    'KIRC': 1,\n",
    "    'COAD': 2,\n",
    "    'LUAD': 3,\n",
    "    'PRAD': 4\n",
    "}\n",
    "labels['Class'] = labels['Class'].map(encoding_dict)\n",
    "\n",
    "\n",
    "\n",
    "#apply k-means clustering\n",
    "#https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html\n",
    "#define the number of clustesr\n",
    "clusters = len(np.unique(labels))\n",
    "#apply kmeans\n",
    "k_means = KMeans(n_clusters=clusters, random_state=42, init='k-means++')\n",
    "#fit the scaled down data\n",
    "\n",
    "# k_means.fit(data_reduced)\n",
    "# y_kmeans = k_means.predict(data_reduced)\n",
    "\n",
    "k_means.fit(X_train_reduced)\n",
    "y_kmeans = k_means.predict(X_train_reduced)\n",
    "\n",
    "#get clusters and centroids\n",
    "cluster_labels = k_means.labels_\n",
    "centroids = k_means.cluster_centers_\n",
    "\n",
    "# #compute the contingency matrix\n",
    "# #https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.cluster.contingency_matrix.html\n",
    "# cont_matrix = contingency_matrix(labels, cluster_labels)\n",
    "\n",
    "# #match each cluster to the true label with the highest count\n",
    "# cluster_label_match = np.argmax(cont_matrix, axis=1)\n",
    "\n",
    "# #map predicted cluster labels to the corresponding true labels\n",
    "# mapped_cluster_labels = np.array([cluster_label_match[label] for label in cluster_labels])\n",
    "\n",
    "\n",
    "\n",
    "#compute the contingency matrix\n",
    "cont_matrix = contingency_matrix(labels, cluster_labels)\n",
    "\n",
    "#solve the optimal alignment problem\n",
    "row_ind, col_ind = linear_sum_assignment(-cont_matrix) # Negative for maximization\n",
    "\n",
    "#map cluster labels to ground truth labels\n",
    "mapped_cluster_labels = np.zeros_like(cluster_labels)\n",
    "for i, j in zip(row_ind, col_ind):\n",
    "    mapped_cluster_labels[cluster_labels == j] = i\n",
    "\n",
    "#accuracy and classificaition report\n",
    "accuracy= accuracy_score(labels, mapped_cluster_labels)\n",
    "# print(labels) TODO remove\n",
    "# print('------')\n",
    "# print(mapped_cluster_labels)\n",
    "classification_r = classification_report(labels, mapped_cluster_labels)\n",
    "\n",
    "print(\"K-Means Report\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report (Test):\\n\", classification_r)\n",
    "\n",
    "#silhouette score with euclidean metric\n",
    "# silhouette_s = silhouette_score(X=data_scaled, labels=cluster_labels, metric='euclidean')\n",
    "# print(f\"Silhouette Score: {silhouette_s:.2f}\")\n",
    "\n",
    "#2d visualization using PCA (reduce to 2 dimensions for plotting)\n",
    "plt.figure(figsize=(10, 8))\n",
    "# sns.scatterplot(x=data_reduced[:, 0], y=data_reduced[:, 1], hue=mapped_cluster_labels, palette='viridis', s=50, alpha=0.8)\n",
    "sns.scatterplot(x=X_train_reduced[:, 0], y=X_train_reduced[:, 1], hue=mapped_cluster_labels, palette='viridis', s=50, alpha=0.8)\n",
    "# plt.scatter(k_means.cluster_centers_[:, 0], k_means.cluster_centers_[:, 1], c='red', s=200, alpha=0.8, label=\"Centroids\")\n",
    "# plt.title(\"KMeans Clusters with PCA\")\n",
    "plt.title(\"Principal Component Analysis\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend(title=\"Cluster\", loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees, AdaBoost & Gradient Boosting - Jack & Dan\n",
    "We next test the boosting algorithms Gradient Boosting and AdaBoost. We conduct a small hyperparameter search over the number of estimators `n_estimators` trained by these ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=10)\n",
    "\n",
    "gradboost = GradientBoostingClassifier(n_estimators=5)\n",
    "\n",
    "rforest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "print('--- Decision Tree ---')\n",
    "val_acc = fit_and_val_sklearn_classifier(classifier=dtree, verbose=True)\n",
    "\n",
    "print('--- AdaBoost ---')\n",
    "val_acc = fit_and_val_sklearn_classifier(classifier=adaboost, verbose=True)\n",
    "\n",
    "print('--- Gradient Boosting ---')\n",
    "val_acc = fit_and_val_sklearn_classifier(classifier=gradboost, verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of performance, both the Gradient Boosting and AdaBoost classifiers achieve >99% validation accuracy and >94% test accuracy on the dataset, though there are some differences in the models. Gradient Boosting achieves this performance reliably, but training is an order of magnitude slower. In contrast, AdaBoost is less reliable, but trains significantly faster even with a larger number of estimators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Hanna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#initalize the SVM model\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "print(\"Support Vector Machine\")\n",
    "#evaluate the svm model\n",
    "val_acc = fit_and_val_sklearn_classifier(classifier=svm_model, verbose=True)\n",
    "\n",
    "#test the model on the test set\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Classification Report (Test): \\n\", classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData()\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = raw_data.get_data()\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_val = imputer.transform(X_val)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "variance_selector = VarianceThreshold(threshold=0.0)\n",
    "X_train = variance_selector.fit_transform(X_train)\n",
    "X_val = variance_selector.transform(X_val)\n",
    "X_test = variance_selector.transform(X_test)\n",
    "\n",
    "feature_names = [feature_names[i] for i in variance_selector.get_support(indices=True)]\n",
    "\n",
    "k = 1000\n",
    "anova_selector = SelectKBest(f_classif, k=min(k, len(feature_names)))\n",
    "X_train_kbest = anova_selector.fit_transform(X_train, y_train)\n",
    "\n",
    "f_scores = anova_selector.scores_\n",
    "p_values = anova_selector.pvalues_\n",
    "\n",
    "if np.isnan(f_scores).any():\n",
    "    print(\"NaN detected in F-scores. Removing invalid features.\")\n",
    "    valid_indices = ~np.isnan(f_scores)\n",
    "    f_scores = f_scores[valid_indices]\n",
    "    p_values = p_values[valid_indices]\n",
    "    feature_names = [feature_names[i] for i in valid_indices]\n",
    "\n",
    "sorted_indices = np.argsort(f_scores)[::-1]\n",
    "sorted_f_scores = f_scores[sorted_indices]\n",
    "sorted_p_values = p_values[sorted_indices]\n",
    "\n",
    "top_features = [feature_names[i] for i in sorted_indices[:k]]\n",
    "\n",
    "print(\"\\nTop 25 Features by ANOVA F-Score:\")\n",
    "for i in range(25):\n",
    "    print(f\"Feature: {top_features[i]}, F-score: {sorted_f_scores[i]:.2f}, p-value: {sorted_p_values[i]:.5e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(k), sorted_f_scores[:k])\n",
    "plt.xlabel('Feature Rank')\n",
    "plt.ylabel('F-Score')\n",
    "plt.title('Top Features Ranked by ANOVA F-Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Sharp Drop in F-Scores:\n",
    "- The plot shows that the first few features have very high F-scores, indicating that they are extremely discriminative.\n",
    "- F-scores decline rapidly, suggesting that most features have diminishing contributions to class discrimination.\n",
    "\n",
    "Feature Redundancy:\n",
    "- After the first few features, the slope becomes more gradual, implying that many features may provide overlapping or redundant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "N = 25  \n",
    "X_train_top = X_train[:, sorted_indices[:N]]\n",
    "X_val_top = X_val[:, sorted_indices[:N]]\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_top, y_train)\n",
    "\n",
    "scores = cross_val_score(rf_model, X_train_top, y_train, cv=5)\n",
    "print(f\"Cross-Validation Accuracy with top {N} features: {np.mean(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in [5, 10, 15, 20, 25, 50, 100]:  \n",
    "    X_train_subset = X_train[:, sorted_indices[:N]]\n",
    "    X_val_subset = X_val[:, sorted_indices[:N]]\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train_subset, y_train)\n",
    "\n",
    "    scores = cross_val_score(rf_model, X_train_subset, y_train, cv=5)\n",
    "    print(f\"Cross-Validation Accuracy with top {N} features: {np.mean(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_f_scores = {}  \n",
    "\n",
    "for cls in classes:\n",
    "    # Create binary labels: 1 for the current class, 0 for all others\n",
    "    y_binary = (y_train == cls).astype(int)\n",
    "    f_scores, p_values = f_classif(X_train, y_binary)\n",
    "    \n",
    "    class_f_scores[cls] = {\n",
    "        'f_scores': f_scores,\n",
    "        'p_values': p_values\n",
    "    }\n",
    "\n",
    "top_n = 10  \n",
    "for cls in classes:\n",
    "    print(f\"\\nTop {top_n} Features for Class {cls}:\")\n",
    "    f_scores = class_f_scores[cls]['f_scores']\n",
    "    sorted_indices = np.argsort(f_scores)[::-1]\n",
    "    \n",
    "    for i in range(top_n):\n",
    "        print(f\"Feature: {feature_names[sorted_indices[i]]}, F-score: {f_scores[sorted_indices[i]]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Train one-vs-rest Random Forest\n",
    "ovr_model = OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "ovr_model.fit(X_train, y_train)\n",
    "\n",
    "top_n = 10  \n",
    "for idx, cls in enumerate(classes):\n",
    "    importances = ovr_model.estimators_[idx].feature_importances_\n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    print(f\"\\nTop {top_n} Features for Class {cls}:\")\n",
    "    for i in range(top_n):\n",
    "        print(f\"Feature: {feature_names[sorted_indices[i]]}, Importance: {importances[sorted_indices[i]]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_top_features = {}\n",
    "\n",
    "for cls in classes:\n",
    "    f_scores = class_f_scores[cls]['f_scores']\n",
    "    sorted_indices = np.argsort(f_scores)[::-1][:top_n]\n",
    "    class_top_features[cls] = [feature_names[i] for i in sorted_indices]\n",
    "\n",
    "print(\"\\nTop Features for Each Class:\")\n",
    "for cls, features in class_top_features.items():\n",
    "    print(f\"Class {cls}: {features}\")\n",
    "\n",
    "for cls in classes:\n",
    "    other_classes = set(classes) - {cls}\n",
    "    other_features = set().union(*(class_top_features[c] for c in other_classes))\n",
    "    unique_features = set(class_top_features[cls]) - other_features\n",
    "    print(f\"\\nUnique Features for Class {cls}: {list(unique_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_features_by_class = {\n",
    "    'BRCA': ['gene_6876', 'gene_6611', 'gene_6530', 'gene_9652', 'gene_6748',\n",
    "             'gene_17801', 'gene_7964', 'gene_15589', 'gene_18746', 'gene_10731'],\n",
    "    'COAD': ['gene_2037', 'gene_7560', 'gene_3523', 'gene_7238', 'gene_5830',\n",
    "             'gene_7554', 'gene_11449', 'gene_12013', 'gene_10098', 'gene_11652'],\n",
    "    'KIRC': ['gene_219', 'gene_1510', 'gene_220', 'gene_12808', 'gene_13818',\n",
    "             'gene_450', 'gene_16246', 'gene_14114', 'gene_16132', 'gene_16169'],\n",
    "    'LUAD': ['gene_11903', 'gene_13639', 'gene_15895', 'gene_15898', 'gene_15899',\n",
    "             'gene_15896', 'gene_15161', 'gene_11352', 'gene_15591', 'gene_15894'],\n",
    "    'PRAD': ['gene_12995', 'gene_9626', 'gene_3737', 'gene_203', 'gene_13976',\n",
    "             'gene_9176', 'gene_9175', 'gene_16358', 'gene_12848', 'gene_18135']\n",
    "}\n",
    "\n",
    "for class_label, unique_features in unique_features_by_class.items():\n",
    "    \n",
    "    class_indices = [feature_names.index(f) for f in unique_features]\n",
    "    \n",
    "    X_train_class = X_train[:, class_indices]\n",
    "    X_test_class = X_test[:, class_indices]\n",
    "    y_train_class = (y_train == class_label).astype(int)  \n",
    "    y_test_class = (y_test == class_label).astype(int)  \n",
    "    \n",
    "    rf_class = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_class.fit(X_train_class, y_train_class)\n",
    "    \n",
    "    y_pred_class = rf_class.predict(X_test_class)\n",
    "    print(f\"Accuracy for {class_label} Classification: {accuracy_score(y_test_class, y_pred_class):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_features_by_class = {\n",
    "    'BRCA': ['gene_6876', 'gene_6611', 'gene_6530', 'gene_9652', 'gene_6748',\n",
    "             'gene_17801', 'gene_7964', 'gene_15589', 'gene_18746', 'gene_10731'],\n",
    "    'COAD': ['gene_2037', 'gene_7560', 'gene_3523', 'gene_7238', 'gene_5830',\n",
    "             'gene_7554', 'gene_11449', 'gene_12013', 'gene_10098', 'gene_11652'],\n",
    "    'KIRC': ['gene_219', 'gene_1510', 'gene_220', 'gene_12808', 'gene_13818',\n",
    "             'gene_450', 'gene_16246', 'gene_14114', 'gene_16132', 'gene_16169'],\n",
    "    'LUAD': ['gene_11903', 'gene_13639', 'gene_15895', 'gene_15898', 'gene_15899',\n",
    "             'gene_15896', 'gene_15161', 'gene_11352', 'gene_15591', 'gene_15894'],\n",
    "    'PRAD': ['gene_12995', 'gene_9626', 'gene_3737', 'gene_203', 'gene_13976',\n",
    "             'gene_9176', 'gene_9175', 'gene_16358', 'gene_12848', 'gene_18135']\n",
    "}\n",
    "\n",
    "for class_label, unique_features in unique_features_by_class.items():\n",
    "    print(f\"\\nGenerating feature importance plot for class {class_label}...\")\n",
    "    \n",
    "    class_indices = [feature_names.index(f) for f in unique_features]\n",
    "    \n",
    "    X_train_class = X_train[:, class_indices]\n",
    "    y_train_class = (y_train == class_label).astype(int)  \n",
    "\n",
    "    rf_class = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_class.fit(X_train_class, y_train_class)\n",
    "    \n",
    "    importances = rf_class.feature_importances_\n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.barh(range(len(unique_features)), importances[sorted_indices], align='center')\n",
    "    plt.yticks(range(len(unique_features)), [unique_features[i] for i in sorted_indices])\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.title(f\"Feature Importance for {class_label} Classification\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "unique_features_by_class = {\n",
    "    'BRCA': ['gene_9652', 'gene_10731', 'gene_17801', 'gene_7964', 'gene_630'],\n",
    "    'COAD': ['gene_12013', 'gene_3523', 'gene_7238', 'gene_2037'],\n",
    "    'KIRC': ['gene_219', 'gene_16132', 'gene_220'],\n",
    "    'LUAD': ['gene_11903', 'gene_15898', 'gene_15895', 'gene_15899'],\n",
    "    'PRAD': ['gene_203', 'gene_18135', 'gene_9176', 'gene_9175', 'gene_3737']\n",
    "}\n",
    "\n",
    "for class_label, unique_features in unique_features_by_class.items():    \n",
    "    class_indices = [feature_names.index(f) for f in unique_features]\n",
    "    \n",
    "    X_train_class = X_train[:, class_indices]\n",
    "    X_test_class = X_test[:, class_indices]\n",
    "    y_train_class = (y_train == class_label).astype(int)  \n",
    "    y_test_class = (y_test == class_label).astype(int)  \n",
    "    \n",
    "    rf_class = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_class.fit(X_train_class, y_train_class)\n",
    "    \n",
    "    y_pred_class = rf_class.predict(X_test_class)\n",
    "    print(f\"Accuracy for {class_label} Classification: {accuracy_score(y_test_class, y_pred_class):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "genes_to_test = {\n",
    "    'BRCA': ['gene_9652', 'gene_10731', 'gene_7964'],\n",
    "    'COAD': ['gene_12013', 'gene_3523', 'gene_7238', 'gene_2037'],\n",
    "    'KIRC': ['gene_219', 'gene_16132', 'gene_220'],\n",
    "    'LUAD': ['gene_11903', 'gene_15898', 'gene_15895', 'gene_15899'],\n",
    "    'PRAD': ['gene_203', 'gene_18135', 'gene_9176', 'gene_9175', 'gene_3737']\n",
    "}\n",
    "\n",
    "for class_label, gene_list in genes_to_test.items():\n",
    "    for gene in gene_list:        \n",
    "        gene_index = feature_names.index(gene)\n",
    "        X_train_gene = X_train[:, [gene_index]]  \n",
    "        X_test_gene = X_test[:, [gene_index]]  \n",
    "        y_train_class = (y_train == class_label).astype(int)  \n",
    "        y_test_class = (y_test == class_label).astype(int)  \n",
    "        \n",
    "        rf_gene = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_gene.fit(X_train_gene, y_train_class)\n",
    "        y_pred_gene = rf_gene.predict(X_test_gene)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test_class, y_pred_gene)\n",
    "        print(f\"Accuracy for {class_label} Classification with {gene}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msai339",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
